{"cells":[{"metadata":{"collapsed":true},"cell_type":"markdown","source":"# MARATONA BEHIND THE CODE 2020\n\n## DESAFIO 2: PARTE 1"},{"metadata":{},"cell_type":"markdown","source":"### Trabalhando com Pipelines do scikit-learn"},{"metadata":{},"cell_type":"code","source":"# Primeiro, realizamos a instalação do scikit-learn versão 0.20.0 no Kernel deste notebook:\n!pip install scikit-learn==0.20.0 --upgrade","execution_count":34,"outputs":[{"output_type":"stream","text":"Requirement already up-to-date: scikit-learn==0.20.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.20.0)\r\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.0) (1.2.0)\r\nRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from scikit-learn==0.20.0) (1.15.4)\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"code","source":"# Em seguida iremos importar diversas bibliotecas que serão utilizadas:\n\nimport json\nimport requests\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold, cross_validate\n\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n","execution_count":57,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importando um .csv de seu projeto no IBM Cloud Pak for Data para o Kernel deste notebook"},{"metadata":{"scrolled":true},"cell_type":"code","source":"import types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_2e29cc98c92249589fb271f5cf851e63 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='Fr6Rl6A4GcKbw34FaMIyWwrxwMYSyiRjXHlIBG4O2LO4',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_2e29cc98c92249589fb271f5cf851e63.get_object(Bucket='desafio2ueder-donotdelete-pr-8l3dh7p4ewnvvl',Key='dataset_desafio_2.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n","execution_count":36,"outputs":[{"output_type":"execute_result","execution_count":36,"data":{"text/plain":"   MATRICULA                       NOME  REPROVACOES_DE  REPROVACOES_EM  \\\n0     502375          Márcia Illiglener               0               0   \n1     397093   Jason Jytereoman Izoimum               0               0   \n2     915288  Bartolomeu Inácio da Gama               0               0   \n3     192652            Fernanda Guedes               1               3   \n4     949491     Alessandre Borba Gomes               1               3   \n\n   REPROVACOES_MF  REPROVACOES_GO  NOTA_DE  NOTA_EM  NOTA_MF  NOTA_GO  INGLES  \\\n0               0               0      6.2      5.8      4.6      5.9     0.0   \n1               0               0      6.0      6.2      5.2      4.5     1.0   \n2               0               0      7.3      6.7      7.1      7.2     0.0   \n3               1               1      0.0      0.0      0.0      0.0     1.0   \n4               1               1      0.0      0.0      0.0      0.0     1.0   \n\n   H_AULA_PRES  TAREFAS_ONLINE  FALTAS       PERFIL  \n0            2               4       3       EXATAS  \n1            2               4       3       EXATAS  \n2            5               0       3      HUMANAS  \n3            4               4       4  DIFICULDADE  \n4            5               2       5  DIFICULDADE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MATRICULA</th>\n      <th>NOME</th>\n      <th>REPROVACOES_DE</th>\n      <th>REPROVACOES_EM</th>\n      <th>REPROVACOES_MF</th>\n      <th>REPROVACOES_GO</th>\n      <th>NOTA_DE</th>\n      <th>NOTA_EM</th>\n      <th>NOTA_MF</th>\n      <th>NOTA_GO</th>\n      <th>INGLES</th>\n      <th>H_AULA_PRES</th>\n      <th>TAREFAS_ONLINE</th>\n      <th>FALTAS</th>\n      <th>PERFIL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>502375</td>\n      <td>Márcia Illiglener</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.2</td>\n      <td>5.8</td>\n      <td>4.6</td>\n      <td>5.9</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>EXATAS</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>397093</td>\n      <td>Jason Jytereoman Izoimum</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>6.2</td>\n      <td>5.2</td>\n      <td>4.5</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>EXATAS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>915288</td>\n      <td>Bartolomeu Inácio da Gama</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.3</td>\n      <td>6.7</td>\n      <td>7.1</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>HUMANAS</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192652</td>\n      <td>Fernanda Guedes</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>DIFICULDADE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>949491</td>\n      <td>Alessandre Borba Gomes</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>5</td>\n      <td>DIFICULDADE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"code","source":"#print(df_data_3.groupby(['PERFIL']).count())","execution_count":40,"outputs":[]},{"metadata":{},"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n\n#delete columns\nclass DropColumns(BaseEstimator, TransformerMixin):\n    def __init__(self, columns):\n        self.columns = columns\n\n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        # Primeiro realizamos a cópia do dataframe 'X' de entrada\n        data = X.copy()\n        # Retornamos um novo dataframe sem as colunas indesejadas\n        return data.drop(labels=self.columns, axis='columns')\n\n# Instanciando uma transformação DropColumns\nrm_columns = DropColumns(\n    columns=[\"MATRICULA\",\"NOME\",\"H_AULA_PRES\",\"TAREFAS_ONLINE\",\"FALTAS\",\"REPROVACOES_DE\",\"REPROVACOES_EM\",\"REPROVACOES_MF\",\"REPROVACOES_GO\"]  # Essa transformação recebe como parâmetro uma lista com os nomes das colunas indesejadas\n)\nprint(rm_columns)\n\n# Visualizando as colunas do dataset original\nprint(\"Colunas do dataset original: \\n\")\nprint(df_data_1.columns)\n\n# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\nrm_columns.fit(X=df_data_1)\n\n# Reconstruindo um DataFrame Pandas com o resultado da transformação\ndf_data_2 = pd.DataFrame.from_records(\n    data=rm_columns.transform(\n        X=df_data_1\n    ),\n)\n\n# Visualizando as colunas do dataset transformado\nprint(\"Colunas do dataset após a transformação ``DropColumns``: \\n\")\nprint(df_data_2.columns)","execution_count":37,"outputs":[{"output_type":"stream","text":"DropColumns(columns=['MATRICULA', 'NOME', 'H_AULA_PRES', 'TAREFAS_ONLINE', 'FALTAS', 'REPROVACOES_DE', 'REPROVACOES_EM', 'REPROVACOES_MF', 'REPROVACOES_GO'])\nColunas do dataset original: \n\nIndex(['MATRICULA', 'NOME', 'REPROVACOES_DE', 'REPROVACOES_EM',\n       'REPROVACOES_MF', 'REPROVACOES_GO', 'NOTA_DE', 'NOTA_EM', 'NOTA_MF',\n       'NOTA_GO', 'INGLES', 'H_AULA_PRES', 'TAREFAS_ONLINE', 'FALTAS',\n       'PERFIL'],\n      dtype='object')\nColunas do dataset após a transformação ``DropColumns``: \n\nIndex(['NOTA_DE', 'NOTA_EM', 'NOTA_MF', 'NOTA_GO', 'INGLES', 'PERFIL'], dtype='object')\n","name":"stdout"}]},{"metadata":{},"cell_type":"code","source":"# Criação de um objeto ``SimpleImputer``\nsi = SimpleImputer(\n    missing_values=np.nan,  # os valores faltantes são do tipo ``np.nan`` (padrão Pandas)\n    strategy='constant',  # a estratégia escolhida é a alteração do valor faltante por uma constante\n    fill_value=0,  # a constante que será usada para preenchimento dos valores faltantes é um int64=0.\n    verbose=0,\n    copy=True\n)\n\n# Visualizando os dados faltantes do dataset após a primeira transformação (df_data_2)\nprint(\"Valores nulos antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_data_2.isnull().sum(axis = 0)))\n\n# Aplicamos o SimpleImputer ``si`` ao conjunto de dados df_data_2 (resultado da primeira transformação)\nsi.fit(X=df_data_2)\n\n# Reconstrução de um novo DataFrame Pandas com o conjunto imputado (df_data_3)\ndf_data_3 = pd.DataFrame.from_records(\n    data=si.transform(\n        X=df_data_2\n    ),  # o resultado SimpleImputer.transform(<<pandas dataframe>>) é lista de listas\n    columns=df_data_2.columns  # as colunas originais devem ser conservadas nessa transformação\n)\n\n# Visualizando os dados faltantes do dataset após a segunda transformação (SimpleImputer) (df_data_3)\nprint(\"Valores nulos no dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_data_3.isnull().sum(axis = 0)))","execution_count":38,"outputs":[{"output_type":"stream","text":"Valores nulos antes da transformação SimpleImputer: \n\nNOTA_DE       0\nNOTA_EM       0\nNOTA_MF       0\nNOTA_GO    3716\nINGLES     3628\nPERFIL        0\ndtype: int64\n\nValores nulos no dataset após a transformação SimpleImputer: \n\nNOTA_DE    0\nNOTA_EM    0\nNOTA_MF    0\nNOTA_GO    0\nINGLES     0\nPERFIL     0\ndtype: int64\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"code","source":"#print(df_data_3[\"PERFIL\"].unique())","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"code","source":"X = df_data_3.drop(\"PERFIL\", axis = 1)\ny = df_data_3.PERFIL","execution_count":39,"outputs":[]},{"metadata":{},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)","execution_count":40,"outputs":[]},{"metadata":{},"cell_type":"code","source":"feats = [\"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\"]\n","execution_count":41,"outputs":[]},{"metadata":{},"cell_type":"code","source":"xgboost = XGBClassifier(\n base_score=0.5,\n booster='gbtree',\n colsample_bylevel=1,\n colsample_bynode=1,\n colsample_bytree=1,\n gamma=0,\n learning_rate=0.1,\n max_delta_step=0,\n max_depth=3,\n max_features='sqrt',\n min_child_weight=1,\n min_samples_split=2,\n missing=None,\n n_estimators=50,\n n_jobs=1,\n nthread=None,\n objective='multi:softprob',\n random_state=0,\n reg_alpha=0,\n reg_lambda=1,\n scale_pos_weight=1,\n seed=None,\n subsample=1,\n)\n\nxgboost.fit(X_train, y_train)\n\ny_pred = xgboost.predict(X_test)\n","execution_count":60,"outputs":[]},{"metadata":{},"cell_type":"code","source":"print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 2)))","execution_count":61,"outputs":[{"output_type":"stream","text":"Acurácia: 82.0%\n","name":"stdout"}]},{"metadata":{},"cell_type":"code","source":"#from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n#print (classification_report(y_test, y_pred))\n","execution_count":32,"outputs":[]},{"metadata":{},"cell_type":"code","source":"#Confusion Matrix \n#print (pd.crosstab(y_test, y_pred, rownames=['Real'], colnames=['Predito'], margins=True))\n","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.6","language":"python"},"language_info":{"name":"python","version":"3.6.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}